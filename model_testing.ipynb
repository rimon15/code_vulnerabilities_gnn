{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "c2c46f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "torch_data_ast = pickle.load(open(\"models/data_lists/torch_data_ast.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99ffe7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.70207399789417"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_num_nodes = 0\n",
    "i = 0\n",
    "for td in torch_data_ast:\n",
    "    tot_num_nodes += td.num_nodes\n",
    "    i += 1\n",
    "tot_num_nodes / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dfac484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.70207399789417"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_num_nodes = 0\n",
    "i = 0\n",
    "for td in torch_data_ast:\n",
    "    tot_num_nodes += td.num_nodes\n",
    "    i += 1\n",
    "tot_num_nodes / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92eec68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_num_edges = 0\n",
    "i = 0\n",
    "for td in torch_data_ast:\n",
    "    tot_num_nodes += td.num_edges\n",
    "    i += 1\n",
    "tot_num_edges / i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf2572",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05b87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52dfd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "\n",
    "b_size = 100\n",
    "train, split1 = train_test_split(torch_data, test_size=.25)\n",
    "test, validate = train_test_split(split1, test_size=.2)\n",
    "train_batches = DataLoader(train, batch_size=b_size, num_workers=4)\n",
    "test_batches = DataLoader(test, batch_size=b_size, num_workers=4)\n",
    "validate_batches = DataLoader(validate, batch_size=b_size, num_workers=4)\n",
    "\n",
    "# for tb in train_batches:\n",
    "#     tb = tb.to(device)\n",
    "#     #print(tb.x)\n",
    "# for tb in test_batches:\n",
    "#     tb = tb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3726a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_layer_by_name = {\n",
    "    \"GCN\": geom_nn.GCNConv,\n",
    "    \"GAT\": geom_nn.GATConv,\n",
    "    \"GraphConv\": geom_nn.GraphConv\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a59fa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden, c_out, num_layers=2, layer_name=\"GCN\", dp_rate=0.1, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of the output features. Usually number of classes in classification\n",
    "            num_layers - Number of \"hidden\" graph layers\n",
    "            layer_name - String of the graph layer to use\n",
    "            dp_rate - Dropout rate to apply throughout the network\n",
    "            kwargs - Additional arguments for the graph layer (e.g. number of heads for GAT)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        gnn_layer = gnn_layer_by_name[layer_name]\n",
    "        \n",
    "        layers = []\n",
    "        in_channels, out_channels = c_in, c_hidden\n",
    "        for l_idx in range(num_layers - 1):\n",
    "            layers += [\n",
    "                gnn_layer(in_channels=in_channels, out_channels=out_channels, **kwargs), nn.ReLU(inplace=True), \n",
    "                nn.Dropout(dp_rate)\n",
    "            ]\n",
    "            in_channels = c_hidden\n",
    "        layers += [gnn_layer(in_channels=in_channels, out_channels=c_out, **kwargs)]\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "        \"\"\"\n",
    "        for l in self.layers:\n",
    "            # For graph layers, we need to add the \"edge_index\" tensor as additional input\n",
    "            # All PyTorch Geometric graph layer inherit the class \"MessagePassing\", hence\n",
    "            # we can simply check the class type.\n",
    "            if isinstance(l, geom_nn.MessagePassing):\n",
    "                x = l(x, edge_index)\n",
    "            else:\n",
    "                x = l(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31fecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphGNNModel(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs - Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in,\n",
    "                            c_hidden=c_hidden,\n",
    "                            c_out=c_hidden, # Not our prediction output yet!\n",
    "                            **kwargs)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dp_rate_linear),\n",
    "            nn.Linear(c_hidden, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx - Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
    "        x = self.head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphLevelGNN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **model_kwargs):\n",
    "        super().__init__()\n",
    "        # Saving hyperparameters\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.model = GraphGNNModel(**model_kwargs)\n",
    "        self.loss_module = nn.BCEWithLogitsLoss() if self.hparams.c_out == 1 else nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, data, mode=\"train\"):\n",
    "        x, edge_index, batch_idx = data.x, data.edge_index, data.batch\n",
    "        x = self.model(x, edge_index, batch_idx)\n",
    "        x = x.squeeze(dim=-1)\n",
    "\n",
    "        if self.hparams.c_out == 1:\n",
    "            preds = (x > 0).float()\n",
    "            data.y = data.y.float()\n",
    "        else:\n",
    "            preds = x.argmax(dim=-1)\n",
    "        loss = self.loss_module(x[0], data.y[0])\n",
    "        #acc = (preds == data.y).sum().float() / preds.shape[0]\n",
    "        acc = torchmetrics.functional.accuracy(preds.int(), data.y.int())\n",
    "        f1 = torchmetrics.functional.f1_score(preds.int(), data.y.int())\n",
    "        print(acc, f1)\n",
    "        #auc = torchmetrics.functional.auc(x, data.y)\n",
    "        return loss, acc, f1\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=1e-2, weight_decay=0.0) # High lr because of small dataset and small model\n",
    "        return optimizer\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, acc, _ = self.forward(batch, mode=\"train\")\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc)\n",
    "        #self.log('train_f1', f1)\n",
    "        #self.log('batch_size', torch.Tensor(b_size).to(torch.float32))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _, acc, _ = self.forward(batch, mode=\"val\")\n",
    "        self.log('val_acc', acc)\n",
    "        #self.log('val_f1', f1)\n",
    "        #self.log('batch_size', torch.Tensor(b_size).to(torch.float32))\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _, acc, f1 = self.forward(batch, mode=\"test\")\n",
    "        self.log('test_acc', acc)\n",
    "        self.log('test_f1', f1)\n",
    "        #self.log('test_f1', f1)\n",
    "        #self.log('batch_size', torch.Tensor(b_size).to(torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e80b689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_graph_classifier(model_name, **model_kwargs):\n",
    "    pl.seed_everything(42)\n",
    "\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(\"test\", \"GraphLevel\" + model_name)\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\")],\n",
    "                         gpus=1 if str(device).startswith(\"cuda\") else 0,\n",
    "                         max_epochs=5,\n",
    "                         progress_bar_refresh_rate=0)\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(\"test\", f\"GraphLevel{model_name}.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = GraphLevelGNN.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)\n",
    "        model = GraphLevelGNN(c_in=100,\n",
    "                              c_out=1,\n",
    "                              **model_kwargs)\n",
    "        trainer.fit(model, train_batches, validate_batches)\n",
    "        model = GraphLevelGNN.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)\n",
    "    # Test best model on validation and test set\n",
    "    train_result = trainer.test(model, dataloaders=validate_batches, verbose=True)\n",
    "    test_result = trainer.test(model, dataloaders=test_batches, verbose=True)\n",
    "    #result = {\"test\": test_result[0]['test_acc'], \"train\": train_result[0]['test_acc']}\n",
    "    return model, train_result, test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d63d7d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, train_result, test_result = train_graph_classifier(model_name=\"GraphGCN\",\n",
    "                                       c_hidden=256,\n",
    "                                       layer_name=\"GCN\",\n",
    "                                       num_layers=3,\n",
    "                                       dp_rate_linear=0.5,\n",
    "                                       dp_rate=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be69807",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57b4b51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7c7bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as geom_nn\n",
    "import torch_geometric.data as geom_data\n",
    "import torch.optim as optim\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "import os\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch_data_ast = pickle.load(open(\"models/data_lists/torch_data_ast.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ef996fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(torch_data_ast)):\n",
    "    #torch_data_ast[i].y = torch.Tensor([1, torch_data_ast[i].y])\n",
    "    torch_data_ast[i] = torch_data_ast[i].to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "566414fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.loader as loader\n",
    "train_loader = loader.DataLoader(torch_data_ast, shuffle=True, batch_size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7b59353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphGNNModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_hidden, c_out, dp_rate_linear=0.5, **kwargs):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            c_in - Dimension of input features\n",
    "            c_hidden - Dimension of hidden features\n",
    "            c_out - Dimension of output features (usually number of classes)\n",
    "            dp_rate_linear - Dropout rate before the linear layer (usually much higher than inside the GNN)\n",
    "            kwargs - Additional arguments for the GNNModel object\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.GNN = GNNModel(c_in=c_in, \n",
    "                            c_hidden=c_hidden, \n",
    "                            c_out=c_hidden, # Not our prediction output yet!\n",
    "                            **kwargs)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Dropout(dp_rate_linear),\n",
    "            nn.Linear(c_hidden, c_out)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, edge_index, batch_idx):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            x - Input features per node\n",
    "            edge_index - List of vertex index pairs representing the edges in the graph (PyTorch geometric notation)\n",
    "            batch_idx - Index of batch element for each node\n",
    "        \"\"\"\n",
    "        x = self.GNN(x, edge_index)\n",
    "        x = geom_nn.global_mean_pool(x, batch_idx) # Average pooling\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d8fbe096",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = geom_nn.GCNConv(100, 256)\n",
    "        self.conv2 = geom_nn.GCNConv(256, 200)\n",
    "        self.linear1 = nn.Linear(200, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.linear1(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        x = x[torch.argmax(x)]\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "63d91224",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [185]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m real_y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([data\u001b[38;5;241m.\u001b[39my])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(pred, real_y)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/_tensor.py:363\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    356\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    357\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    361\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    362\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 363\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    for data in torch_data_ast:\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        pred = model(data)\n",
    "        real_y = torch.Tensor([data.y]).to(device)\n",
    "        loss = criterion(pred, real_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "#         all_labels.append(batch.y.cpu().detach().numpy())\n",
    "        \n",
    "        \n",
    "#     out = model(data)\n",
    "#     print(data.y)\n",
    "#     loss = F.cross_entropy(out, torch.Tensor(data.y))\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b2100",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(data).argmax(dm=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9300a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fb38e639",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f6183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422890f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5127f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2af9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, model_params):\n",
    "        super().__init__()\n",
    "        embedding_size = 100\n",
    "        dense_neurons = 256\n",
    "        self.conv1 = geom_nn.GCNConv(100, 16)\n",
    "        self.conv2 = geom_nn.GCNConv(16, 1)\n",
    "        # Linear layers\n",
    "        self.linear1 = Linear(embedding_size*2, dense_neurons)\n",
    "        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n",
    "        self.linear3 = Linear(int(dense_neurons/2), 1)  \n",
    "\n",
    "    def forward(self, x, batch_index):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index, batch_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index, batch_index)\n",
    "\n",
    "        # Holds the intermediate graph representations\n",
    "        global_representation = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
    "            x = torch.relu(self.transf_layers[i](x))\n",
    "            x = self.bn_layers[i](x)\n",
    "            # Always aggregate last layer\n",
    "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
    "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](\n",
    "                    x, edge_index, edge_attr, batch_index\n",
    "                    )\n",
    "                # Add current representation\n",
    "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
    "    \n",
    "        x = sum(global_representation)\n",
    "\n",
    "        # Output block\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8831e230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, train_loader, optimizer, loss_fn):\n",
    "    # Enumerate over the data\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    running_loss = 0.0\n",
    "    step = 0\n",
    "    for _, batch in enumerate(tqdm(train_loader)):\n",
    "        # Use GPU\n",
    "        batch.to(device)  \n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad() \n",
    "        # Passing the node features and the connection info\n",
    "        pred = model(batch.x.float(), \n",
    "                                batch.edge_attr.float(),\n",
    "                                batch.edge_index, \n",
    "                                batch.batch) \n",
    "        # Calculating the loss and gradients\n",
    "        loss = loss_fn(torch.squeeze(pred), batch.y.float())\n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        # Update tracking\n",
    "        running_loss += loss.item()\n",
    "        step += 1\n",
    "        all_preds.append(np.rint(torch.sigmoid(pred).cpu().detach().numpy()))\n",
    "        all_labels.append(batch.y.cpu().detach().numpy())\n",
    "    all_preds = np.concatenate(all_preds).ravel()\n",
    "    all_labels = np.concatenate(all_labels).ravel()\n",
    "    calculate_metrics(all_preds, all_labels, epoch, \"train\")\n",
    "    return running_loss/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fd048040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch_geometric.loader.dataloader.DataLoader at 0x7efe930fba30>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccae17d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a559ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7ded3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "3a00653a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn.conv import GatedGraphConv\n",
    "\n",
    "\n",
    "def get_conv_mp_out_size(in_size, last_layer, mps):\n",
    "    size = in_size\n",
    "\n",
    "    for mp in mps:\n",
    "        size = round((size - mp[\"kernel_size\"]) / mp[\"stride\"] + 1)\n",
    "\n",
    "    size = size + 1 if size % 2 != 0 else size\n",
    "\n",
    "    return int(size * last_layer[\"out_channels\"])\n",
    "\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m) == nn.Conv1d:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "class Conv(nn.Module):\n",
    "\n",
    "    def __init__(self, conv1d_1, conv1d_2, maxpool1d_1, maxpool1d_2, fc_1_size, fc_2_size):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv1d_1_args = conv1d_1\n",
    "        self.conv1d_1 = nn.Conv1d(**conv1d_1)\n",
    "        self.conv1d_2 = nn.Conv1d(**conv1d_2)\n",
    "\n",
    "        fc1_size = get_conv_mp_out_size(fc_1_size, conv1d_2, [maxpool1d_1, maxpool1d_2])\n",
    "        fc2_size = get_conv_mp_out_size(fc_2_size, conv1d_2, [maxpool1d_1, maxpool1d_2])\n",
    "\n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(fc1_size, 1)\n",
    "        self.fc2 = nn.Linear(fc2_size, 1)\n",
    "\n",
    "        # Dropout\n",
    "        self.drop = nn.Dropout(p=0.2)\n",
    "\n",
    "        self.mp_1 = nn.MaxPool1d(**maxpool1d_1)\n",
    "        self.mp_2 = nn.MaxPool1d(**maxpool1d_2)\n",
    "\n",
    "    def forward(self, hidden, x):\n",
    "        concat = torch.cat([hidden, x], 1)\n",
    "        print(x.shape)\n",
    "        concat_size = hidden.shape[1] + x.shape[1]\n",
    "        print('sizes', self.conv1d_1_args[\"in_channels\"], concat_size)\n",
    "        print(concat.size())\n",
    "        print(concat)\n",
    "        concat = concat.view(-1, self.conv1d_1_args[\"in_channels\"], concat_size)\n",
    "        #concat = concat.view(-1, self.conv1d_1_args[\"in_channels\"], concat_size)\n",
    "\n",
    "        Z = self.mp_1(F.relu(self.conv1d_1(concat)))\n",
    "        Z = self.mp_2(self.conv1d_2(Z))\n",
    "        \n",
    "        hidden = hidden.view(-1, self.conv1d_1_args[\"in_channels\"], hidden.shape[1])\n",
    "\n",
    "        Y = self.mp_1(F.relu(self.conv1d_1(hidden)))\n",
    "        Y = self.mp_2(self.conv1d_2(Y))\n",
    "\n",
    "        Z_flatten_size = int(Z.shape[1] * Z.shape[-1])\n",
    "        Y_flatten_size = int(Y.shape[1] * Y.shape[-1])\n",
    "\n",
    "        Z = Z.view(-1, Z_flatten_size)\n",
    "        Y = Y.view(-1, Y_flatten_size)\n",
    "        res = self.fc1(Z) * self.fc2(Y)\n",
    "        res = self.drop(res)\n",
    "        # res = res.mean(1)\n",
    "        # print(res, mean)\n",
    "        sig = torch.sigmoid(torch.flatten(res))\n",
    "        return sig\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, gated_graph_conv_args, conv_args, emb_size, device):\n",
    "        super(Net, self).__init__()\n",
    "        self.ggc = GatedGraphConv(**gated_graph_conv_args).to(device)\n",
    "        self.conv = Conv(**conv_args,\n",
    "                         fc_1_size=gated_graph_conv_args[\"out_channels\"],\n",
    "                         fc_2_size=gated_graph_conv_args[\"out_channels\"]).to(device)\n",
    "        # self.conv.apply(init_weights)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.ggc(x, edge_index)\n",
    "        x = self.conv(x, data.x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load(self, path):\n",
    "        self.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "dda9cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE metrics.py\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(self, outs, labels):\n",
    "        self.scores = outs\n",
    "        self.labels = labels\n",
    "        self.transform()\n",
    "        print(self.predicts)\n",
    "\n",
    "    def transform(self):\n",
    "        self.series = pd.Series(self.scores)\n",
    "        self.predicts = self.series.apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "        self.predicts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    def __str__(self):\n",
    "        confusion = confusion_matrix(y_true=self.labels, y_pred=self.predicts)\n",
    "        tn, fp, fn, tp = confusion.ravel()\n",
    "        string = f\"\\nConfusion matrix: \\n\"\n",
    "        string += f\"{confusion}\\n\"\n",
    "        string += f\"TP: {tp}, FP: {fp}, TN: {tn}, FN: {fn}\\n\"\n",
    "        string += '\\n'.join([name + \": \" + str(metric) for name, metric in self().items()])\n",
    "        return string\n",
    "\n",
    "    def __call__(self):\n",
    "        _metrics = {\"Accuracy\": metrics.accuracy_score(y_true=self.labels, y_pred=self.predicts),\n",
    "                    \"Precision\": metrics.precision_score(y_true=self.labels, y_pred=self.predicts),\n",
    "                    \"Recall\": metrics.recall_score(y_true=self.labels, y_pred=self.predicts),\n",
    "                    \"F-measure\": metrics.f1_score(y_true=self.labels, y_pred=self.predicts),\n",
    "                    \"Precision-Recall AUC\": metrics.average_precision_score(y_true=self.labels, y_score=self.scores),\n",
    "                    \"AUC\": metrics.roc_auc_score(y_true=self.labels, y_score=self.scores),\n",
    "                    \"MCC\": metrics.matthews_corrcoef(y_true=self.labels, y_pred=self.predicts),\n",
    "                    \"Error\": self.error()}\n",
    "\n",
    "        return _metrics\n",
    "\n",
    "    def log(self):\n",
    "        excluded = [\"Precision-Recall AUC\", \"AUC\"]\n",
    "        _metrics = self()\n",
    "        print(_metrics)\n",
    "#         msg = ' - '.join(\n",
    "#             [f\"({name[:3]} {round(metric, 3)})\" for name, metric in _metrics.items() if name not in excluded])\n",
    "\n",
    "#         print('metrics', msg)\n",
    "\n",
    "    def error(self):\n",
    "        errors = [(abs(score - (1 if score >= 0.5 else 0))/score)*100 for score, label in zip(self.scores, self.labels)]\n",
    "\n",
    "        return sum(errors)/len(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "38a63221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE modeling.py\n",
    "\n",
    "import torch\n",
    "import time\n",
    "\n",
    "class Train(object):\n",
    "    def __init__(self, step, epochs, verbose=True):\n",
    "        self.epochs = epochs\n",
    "        self.step = step\n",
    "        self.history = History()\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def __call__(self, train_loader_step, val_loader_step=None, early_stopping=None):\n",
    "        for epoch in range(self.epochs):\n",
    "            print('training')\n",
    "            self.step.train()\n",
    "            train_stats = train_loader_step(self.step)\n",
    "            self.history(train_stats, epoch + 1)\n",
    "\n",
    "            if val_loader_step is not None:\n",
    "                with torch.no_grad():\n",
    "                    self.step.eval()\n",
    "                    val_stats = val_loader_step(self.step)\n",
    "                    self.history(val_stats, epoch + 1)\n",
    "\n",
    "                print(self.history)\n",
    "\n",
    "                if early_stopping is not None:\n",
    "                    valid_loss = val_stats.loss()\n",
    "                    # early_stopping needs the validation loss to check if it has decreased,\n",
    "                    # and if it has, it will make a checkpoint of the current model\n",
    "                    if early_stopping(valid_loss):\n",
    "                        self.history.log()\n",
    "                        return\n",
    "            else:\n",
    "                print(self.history)\n",
    "        self.history.log()\n",
    "\n",
    "\n",
    "def predict(step, test_loader_step):\n",
    "    print(f\"Testing\")\n",
    "    with torch.no_grad():\n",
    "        step.eval()\n",
    "        stats = test_loader_step(step)\n",
    "        metrics = Metrics(outs(), labels())\n",
    "        print(metrics)\n",
    "        metrics.log()\n",
    "    return metrics()[\"Accuracy\"]\n",
    "\n",
    "\n",
    "class History:\n",
    "    def __init__(self):\n",
    "        self.history = {}\n",
    "        self.epoch = 0\n",
    "        self.timer = time.time()\n",
    "\n",
    "    def __call__(self, stats, epoch):\n",
    "        self.epoch = epoch\n",
    "\n",
    "        if epoch in self.history:\n",
    "            self.history[epoch].append(stats)\n",
    "        else:\n",
    "            self.history[epoch] = [stats]\n",
    "\n",
    "    def __str__(self):\n",
    "        epoch = f\"\\nEpoch {self.epoch};\"\n",
    "        stats = ' - '.join([f\"{res}\" for res in self.current()])\n",
    "        timer = f\"Time: {(time.time() - self.timer)}\"\n",
    "\n",
    "        return f\"{epoch} - {stats} - {timer}\"\n",
    "\n",
    "    def current(self):\n",
    "        return self.history[self.epoch]\n",
    "\n",
    "    def log(self):\n",
    "        msg = f\"(Epoch: {self.epoch}) {' - '.join([f'({res})' for res in self.current()])}\"\n",
    "        print(\"history\", msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "b57f79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE stats.py\n",
    "\n",
    "import dataclasses\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Stat:\n",
    "    def __init__(self, outs=None, loss=0.0, acc=0.0, labels=None):\n",
    "        if labels is None:\n",
    "            labels = []\n",
    "        if outs is None:\n",
    "            outs = []\n",
    "        self.outs = outs\n",
    "        self.labels = labels\n",
    "        self.loss = loss\n",
    "        self.acc = acc\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Stat(self.outs + other.outs, self.loss + other.loss, self.acc + other.acc, self.labels + other.labels)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Loss: {round(self.loss, 4)}; Acc: {round(self.acc, 4)};\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Stats:\n",
    "    name: str\n",
    "    results: List[Stat] = dataclasses.field(default_factory=list)\n",
    "    total: Stat = Stat()\n",
    "\n",
    "    def __call__(self, stat):\n",
    "        self.total += stat\n",
    "        self.results.append(stat)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name} {self.mean()}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.results)\n",
    "\n",
    "    def mean(self):\n",
    "        res = Stat()\n",
    "        res += self.total\n",
    "        res.loss /= len(self)\n",
    "        res.acc /= len(self)\n",
    "\n",
    "        return res\n",
    "\n",
    "    def loss(self):\n",
    "        return self.mean().loss\n",
    "\n",
    "    def acc(self):\n",
    "        return self.mean().acc\n",
    "\n",
    "    def outs(self):\n",
    "        return self.total.outs\n",
    "\n",
    "    def labels(self):\n",
    "        return self.total.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "f6ee188f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE step.py\n",
    "import torch\n",
    "\n",
    "def softmax_accuracy(probs, all_labels):\n",
    "    acc = (torch.argmax(probs) == all_labels).sum()\n",
    "    acc = torch.div(acc, len(all_labels) + 0.0)\n",
    "    return acc\n",
    "\n",
    "\n",
    "class Step:\n",
    "    # Performs a step on the loader and returns the result\n",
    "    def __init__(self, model, loss_function, optimizer):\n",
    "        self.model = model\n",
    "        self.criterion = loss_function\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def __call__(self, i, x, y):\n",
    "        out = self.model(x)\n",
    "        loss = self.criterion(out, y.float())\n",
    "        acc = softmax_accuracy(out, y.float())\n",
    "\n",
    "        if self.model.training:\n",
    "            # calculates the gradient\n",
    "            loss.backward()\n",
    "            # and performs a parameter update based on it\n",
    "            self.optimizer.step()\n",
    "            # clears old gradients from the last step\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "        # print(f\"\\tBatch: {i}; Loss: {round(loss.item(), 4)}\", end=\"\")\n",
    "        return Stat(out.tolist(), loss.item(), acc.item(), y.tolist())\n",
    "\n",
    "    def train(self):\n",
    "        self.model.train()\n",
    "\n",
    "    def eval(self):\n",
    "        self.model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "f60a6720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE devign.py\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Devign(Step):\n",
    "    def __init__(self,\n",
    "                 path: str,\n",
    "                 device: str,\n",
    "                 model: dict,\n",
    "                 learning_rate: float,\n",
    "                 weight_decay: float,\n",
    "                 loss_lambda: float):\n",
    "        self.path = path\n",
    "        self.lr = learning_rate\n",
    "        self.wd = weight_decay\n",
    "        self.ll = loss_lambda\n",
    "        print('devign', f\"LR: {self.lr}; WD: {self.wd}; LL: {self.ll};\")\n",
    "        _model = Net(**model, device=device)\n",
    "        super().__init__(model=_model,\n",
    "                         loss_function=lambda o, t: F.binary_cross_entropy(o, t) + F.l1_loss(o, t) * self.ll,\n",
    "                         optimizer=optim.Adam(_model.parameters(), lr=self.lr, weight_decay=self.wd),\n",
    "                         )\n",
    "\n",
    "        self.count_parameters()\n",
    "\n",
    "    def load(self):\n",
    "        self.model.load(self.path)\n",
    "\n",
    "    def save(self):\n",
    "        self.model.save(self.path)\n",
    "\n",
    "    def count_parameters(self):\n",
    "        count = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print(f\"The model has {count:,} trainable parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "df91b1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILE LoaderStep.py\n",
    "\n",
    "class LoaderStep:\n",
    "    def __init__(self, name, data_loader, device):\n",
    "        self.name = name\n",
    "        self.loader = data_loader\n",
    "        self.size = len(data_loader)\n",
    "        self.device = device\n",
    "\n",
    "    def __call__(self, step):\n",
    "        self.stats = Stats(self.name)\n",
    "\n",
    "        for i, batch in enumerate(self.loader):\n",
    "            batch.to(self.device)\n",
    "            stat: Stat = step(i, batch, batch.y)\n",
    "            self.stats(stat)\n",
    "\n",
    "        return self.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "1cfb5128",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "    \"gated_graph_conv_args\": {\"out_channels\" : 200, \"num_layers\" : 6, \"aggr\" : \"add\", \"bias\": True},\n",
    "    \"conv_args\": {\n",
    "        \"conv1d_1\" : {\"in_channels\": 300, \"out_channels\": 50, \"kernel_size\": 3, \"padding\" : 1},\n",
    "        \"conv1d_2\" : {\"in_channels\": 50, \"out_channels\": 20, \"kernel_size\": 1, \"padding\" : 1},\n",
    "        \"maxpool1d_1\" : {\"kernel_size\" : 3, \"stride\" : 2},\n",
    "        \"maxpool1d_2\" : {\"kernel_size\" : 2, \"stride\" : 2}\n",
    "    },\n",
    "    \"emb_size\" : 101\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "a55f6e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devign LR: 0.0001; WD: 1.3e-06; LL: 1.3e-06;\n",
      "The model has 529,272 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = Devign(path=\"test/devign\", device='cuda', model=model_kwargs, learning_rate=1e-4,\n",
    "              weight_decay=1.3e-6, loss_lambda=1.3e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "8872b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Train(model, 10)\n",
    "b_size = 1\n",
    "train, split1 = train_test_split(torch_data_ast, test_size=.25)\n",
    "test, validate = train_test_split(split1, test_size=.2)\n",
    "train_loader = DataLoader(train, batch_size=b_size, num_workers=4)\n",
    "test_loader = DataLoader(test, batch_size=b_size, num_workers=4)\n",
    "val_loader = DataLoader(validate, batch_size=b_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "ecc0bcdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "torch.Size([26, 100])\n",
      "sizes 300 300\n",
      "torch.Size([26, 300])\n",
      "tensor([[-0.0566, -0.1202,  0.0139,  ...,  0.2977,  1.2501,  0.0073],\n",
      "        [-0.0800, -0.1284,  0.0105,  ...,  0.3040,  0.6941, -0.4551],\n",
      "        [-0.0632, -0.1252,  0.0095,  ..., -0.0045,  0.6536, -0.3779],\n",
      "        ...,\n",
      "        [-0.0528, -0.1172,  0.0185,  ...,  0.5362,  0.1098, -0.0150],\n",
      "        [-0.0446, -0.1083,  0.0115,  ...,  0.9393,  0.7493, -0.3109],\n",
      "        [-0.0739, -0.0803,  0.0144,  ..., -1.0864,  0.3944,  0.5768]],\n",
      "       device='cuda:0', grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [50, 300, 3], expected input[1, 26, 300] to have 300 channels, but got 26 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [621]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m val_loader_step \u001b[38;5;241m=\u001b[39m LoaderStep(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation\u001b[39m\u001b[38;5;124m\"\u001b[39m, val_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_loader_step \u001b[38;5;241m=\u001b[39m LoaderStep(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_loader, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader_step\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [613]\u001b[0m, in \u001b[0;36mTrain.__call__\u001b[0;34m(self, train_loader_step, val_loader_step, early_stopping)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 17\u001b[0m train_stats \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loader_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory(train_stats, epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loader_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Input \u001b[0;32mIn [617]\u001b[0m, in \u001b[0;36mLoaderStep.__call__\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader):\n\u001b[1;32m     14\u001b[0m     batch\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 15\u001b[0m     stat: Stat \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats(stat)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats\n",
      "Input \u001b[0;32mIn [615]\u001b[0m, in \u001b[0;36mStep.__call__\u001b[0;34m(self, i, x, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, i, x, y):\n\u001b[0;32m---> 18\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(out, y\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     20\u001b[0m     acc \u001b[38;5;241m=\u001b[39m softmax_accuracy(out, y\u001b[38;5;241m.\u001b[39mfloat())\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [611]\u001b[0m, in \u001b[0;36mNet.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     89\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     90\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mggc(x, edge_index)\n\u001b[0;32m---> 91\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [611]\u001b[0m, in \u001b[0;36mConv.forward\u001b[0;34m(self, hidden, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m concat \u001b[38;5;241m=\u001b[39m concat\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_1_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m#concat = concat.view(-1, self.conv1d_1_args[\"in_channels\"], concat_size)\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_1(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m     58\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmp_2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_2(Z))\n\u001b[1;32m     60\u001b[0m hidden \u001b[38;5;241m=\u001b[39m hidden\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1d_1_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_channels\u001b[39m\u001b[38;5;124m\"\u001b[39m], hidden\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/nn/modules/conv.py:302\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/raid0_24TB/rimon/miniconda3/envs/pytorch-build/lib/python3.8/site-packages/torch/nn/modules/conv.py:298\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    296\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    297\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [50, 300, 3], expected input[1, 26, 300] to have 300 channels, but got 26 channels instead"
     ]
    }
   ],
   "source": [
    "train_loader_step = LoaderStep(\"Train\", train_loader, 'cuda')\n",
    "val_loader_step = LoaderStep(\"Validation\", val_loader, 'cuda')\n",
    "test_loader_step = LoaderStep(\"Test\", test_loader, 'cuda')\n",
    "\n",
    "trainer(train_loader_step, val_loader_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aebae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
